<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title></title>
  <meta name="description" content="">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="linear-regression-with-one-predictor-variable.html">
<link rel="next" href="diagnostics-and-remedial-measures.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Notebook for ALRM</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a></li>
<li class="chapter" data-level="2" data-path="linear-regression-with-one-predictor-variable.html"><a href="linear-regression-with-one-predictor-variable.html"><i class="fa fa-check"></i><b>2</b> Linear regression with one predictor variable</a><ul>
<li class="chapter" data-level="2.1" data-path="linear-regression-with-one-predictor-variable.html"><a href="linear-regression-with-one-predictor-variable.html#relations-between-variables"><i class="fa fa-check"></i><b>2.1</b> Relations between variables</a></li>
<li class="chapter" data-level="2.2" data-path="linear-regression-with-one-predictor-variable.html"><a href="linear-regression-with-one-predictor-variable.html#regression-models-and-their-uses"><i class="fa fa-check"></i><b>2.2</b> Regression Models and Their Uses</a></li>
<li class="chapter" data-level="2.3" data-path="linear-regression-with-one-predictor-variable.html"><a href="linear-regression-with-one-predictor-variable.html#simple-linear-regression-model-with-distribution-of-error-terms-unspecified"><i class="fa fa-check"></i><b>2.3</b> Simple linear regression model with distribution of error terms unspecified</a></li>
<li class="chapter" data-level="2.4" data-path="linear-regression-with-one-predictor-variable.html"><a href="linear-regression-with-one-predictor-variable.html#data-for-regression-analysis"><i class="fa fa-check"></i><b>2.4</b> Data for regression analysis</a></li>
<li class="chapter" data-level="2.5" data-path="linear-regression-with-one-predictor-variable.html"><a href="linear-regression-with-one-predictor-variable.html#overview-of-steps-in-regression-analysis"><i class="fa fa-check"></i><b>2.5</b> Overview of steps in regression analysis</a></li>
<li class="chapter" data-level="2.6" data-path="linear-regression-with-one-predictor-variable.html"><a href="linear-regression-with-one-predictor-variable.html#estimation-of-regression-function"><i class="fa fa-check"></i><b>2.6</b> Estimation of regression function</a></li>
<li class="chapter" data-level="2.7" data-path="linear-regression-with-one-predictor-variable.html"><a href="linear-regression-with-one-predictor-variable.html#estimation-of-erro-terms-variance-sigma2"><i class="fa fa-check"></i><b>2.7</b> Estimation of Erro Terms Variance <span class="math inline">\(\sigma^{2}\)</span></a></li>
<li class="chapter" data-level="2.8" data-path="linear-regression-with-one-predictor-variable.html"><a href="linear-regression-with-one-predictor-variable.html#normal-error-regression-model"><i class="fa fa-check"></i><b>2.8</b> Normal Error Regression Model</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html"><i class="fa fa-check"></i><b>3</b> Inferences in Regeression and Correlation Analysis</a><ul>
<li class="chapter" data-level="3.1" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#inferences-concerning-beta_1"><i class="fa fa-check"></i><b>3.1</b> Inferences Concerning <span class="math inline">\(\beta_{1}\)</span></a></li>
<li class="chapter" data-level="3.2" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#inferences-concerning-beta_0"><i class="fa fa-check"></i><b>3.2</b> Inferences Concerning <span class="math inline">\(\beta_{0}\)</span></a></li>
<li class="chapter" data-level="3.3" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#some-considerations-on-making-inferences-concerning-beta_0-and-beta_1"><i class="fa fa-check"></i><b>3.3</b> Some Considerations on Making Inferences Concerning <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span></a></li>
<li class="chapter" data-level="3.4" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#interval-estimation-of-ey_h"><i class="fa fa-check"></i><b>3.4</b> Interval Estimation of <span class="math inline">\(E(Y_{h})\)</span></a></li>
<li class="chapter" data-level="3.5" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#prediction-of-new-observation"><i class="fa fa-check"></i><b>3.5</b> Prediction of New Observation</a></li>
<li class="chapter" data-level="3.6" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#confidence-band-for-regression-line"><i class="fa fa-check"></i><b>3.6</b> Confidence Band for Regression Line</a></li>
<li class="chapter" data-level="3.7" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#analysis-of-variance-approach"><i class="fa fa-check"></i><b>3.7</b> Analysis of Variance Approach</a></li>
<li class="chapter" data-level="3.8" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#general-linear-test-approach"><i class="fa fa-check"></i><b>3.8</b> General Linear Test Approach</a></li>
<li class="chapter" data-level="3.9" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#descriptive-measures-of-linear-association-between-x-and-y"><i class="fa fa-check"></i><b>3.9</b> Descriptive Measures of Linear Association between X and Y</a></li>
<li class="chapter" data-level="3.10" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#considerations-in-applying-regression-analysis"><i class="fa fa-check"></i><b>3.10</b> Considerations in Applying Regression Analysis</a></li>
<li class="chapter" data-level="3.11" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#normal-correlation-models"><i class="fa fa-check"></i><b>3.11</b> Normal Correlation Models</a></li>
<li class="chapter" data-level="3.12" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#r-code"><i class="fa fa-check"></i><b>3.12</b> R code</a><ul>
<li class="chapter" data-level="3.12.1" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#example-data"><i class="fa fa-check"></i><b>3.12.1</b> Example data</a></li>
<li class="chapter" data-level="3.12.2" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#built-in-function"><i class="fa fa-check"></i><b>3.12.2</b> built-in function</a></li>
<li class="chapter" data-level="3.12.3" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#point-estimator-b_0-and-b_1"><i class="fa fa-check"></i><b>3.12.3</b> point estimator <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span></a></li>
<li class="chapter" data-level="3.12.4" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#residuals-sse-and-mse"><i class="fa fa-check"></i><b>3.12.4</b> Residuals, SSE and MSE</a></li>
<li class="chapter" data-level="3.12.5" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#sampling-distribution-of-b_1-and-b_1beta_1sb_1"><i class="fa fa-check"></i><b>3.12.5</b> sampling distribution of <span class="math inline">\(b_1\)</span> and <span class="math inline">\((b_1−\beta_1)/s(b_1)\)</span></a></li>
<li class="chapter" data-level="3.12.6" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#f-test"><i class="fa fa-check"></i><b>3.12.6</b> F test</a></li>
<li class="chapter" data-level="3.12.7" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#r2-and-r"><i class="fa fa-check"></i><b>3.12.7</b> <span class="math inline">\(R^2\)</span> and r</a></li>
<li class="chapter" data-level="3.12.8" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#plot"><i class="fa fa-check"></i><b>3.12.8</b> plot</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="diagnostics-and-remedial-measures.html"><a href="diagnostics-and-remedial-measures.html"><i class="fa fa-check"></i><b>4</b> Diagnostics and Remedial Measures</a></li>
<li class="chapter" data-level="5" data-path="simultaneous-inferences-and-other-topics-in-regression-analysis.html"><a href="simultaneous-inferences-and-other-topics-in-regression-analysis.html"><i class="fa fa-check"></i><b>5</b> Simultaneous Inferences and Other Topics in Regression Analysis</a></li>
<li class="chapter" data-level="6" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html"><i class="fa fa-check"></i><b>6</b> Matrix Approach to Simple Linear Regression Analysis</a><ul>
<li class="chapter" data-level="6.1" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#matrices"><i class="fa fa-check"></i><b>6.1</b> Matrices</a></li>
<li class="chapter" data-level="6.2" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#matrix-addition-and-subtraction"><i class="fa fa-check"></i><b>6.2</b> Matrix Addition and Subtraction</a></li>
<li class="chapter" data-level="6.3" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#matrix-multiplication"><i class="fa fa-check"></i><b>6.3</b> Matrix Multiplication</a></li>
<li class="chapter" data-level="6.4" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#special-types-of-matrices"><i class="fa fa-check"></i><b>6.4</b> Special Types of Matrices</a></li>
<li class="chapter" data-level="6.5" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#linear-dependence-and-rank-of-matrix"><i class="fa fa-check"></i><b>6.5</b> Linear Dependence and Rank of Matrix</a></li>
<li class="chapter" data-level="6.6" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#inverse-of-a-matrix"><i class="fa fa-check"></i><b>6.6</b> Inverse of a Matrix</a></li>
<li class="chapter" data-level="6.7" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#some-basic-results-for-matrics"><i class="fa fa-check"></i><b>6.7</b> Some Basic Results for Matrics</a></li>
<li class="chapter" data-level="6.8" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#random-vectors-and-matrices"><i class="fa fa-check"></i><b>6.8</b> Random Vectors and Matrices</a></li>
<li class="chapter" data-level="6.9" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#simple-linear-regression-model-in-matrix-terms"><i class="fa fa-check"></i><b>6.9</b> Simple Linear Regression Model in Matrix Terms</a></li>
<li class="chapter" data-level="6.10" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#leasst-squares-estimation-of-regression-parameters"><i class="fa fa-check"></i><b>6.10</b> Leasst Squares Estimation of Regression Parameters</a></li>
<li class="chapter" data-level="6.11" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#fitted-values-and-residuals"><i class="fa fa-check"></i><b>6.11</b> Fitted Values and Residuals</a></li>
<li class="chapter" data-level="6.12" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#analysis-of-variance-results"><i class="fa fa-check"></i><b>6.12</b> Analysis of Variance Results</a></li>
<li class="chapter" data-level="6.13" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#inferences-in-regeression-analysis"><i class="fa fa-check"></i><b>6.13</b> Inferences in Regeression Analysis</a></li>
<li class="chapter" data-level="6.14" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#r-code-1"><i class="fa fa-check"></i><b>6.14</b> R code</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="multiple-linear-regression-i.html"><a href="multiple-linear-regression-i.html"><i class="fa fa-check"></i><b>7</b> Multiple linear regression I</a><ul>
<li class="chapter" data-level="7.1" data-path="multiple-linear-regression-i.html"><a href="multiple-linear-regression-i.html#multiple-regression-models"><i class="fa fa-check"></i><b>7.1</b> Multiple Regression Models</a><ul>
<li class="chapter" data-level="7.1.1" data-path="multiple-linear-regression-i.html"><a href="multiple-linear-regression-i.html#first-order-model-with-two-predictor-variables"><i class="fa fa-check"></i><b>7.1.1</b> First-Order Model with Two Predictor Variables</a></li>
<li class="chapter" data-level="7.1.2" data-path="multiple-linear-regression-i.html"><a href="multiple-linear-regression-i.html#first-order-model-with-more-than-two-predictor-variables"><i class="fa fa-check"></i><b>7.1.2</b> First-Order Model with More than Two Predictor Variables</a></li>
<li class="chapter" data-level="7.1.3" data-path="multiple-linear-regression-i.html"><a href="multiple-linear-regression-i.html#general-linear-regression-model"><i class="fa fa-check"></i><b>7.1.3</b> General Linear Regression Model</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="multiple-linear-regression-i.html"><a href="multiple-linear-regression-i.html#general-linear-regression-model-in-matrix-terms"><i class="fa fa-check"></i><b>7.2</b> General Linear Regression Model in Matrix Terms</a></li>
<li class="chapter" data-level="7.3" data-path="multiple-linear-regression-i.html"><a href="multiple-linear-regression-i.html#estimation-of-regression-coefficients"><i class="fa fa-check"></i><b>7.3</b> Estimation of Regression Coefficients</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="multiple-regression-ii.html"><a href="multiple-regression-ii.html"><i class="fa fa-check"></i><b>8</b> Multiple Regression II</a><ul>
<li class="chapter" data-level="8.1" data-path="multiple-regression-ii.html"><a href="multiple-regression-ii.html#extra-sums-of-squares"><i class="fa fa-check"></i><b>8.1</b> Extra Sums of Squares</a></li>
</ul></li>
<li class="divider"></li>
Published with <a href="https://github.com/rstudio/bookdown" target="blank">bookdown</a> by <a href="http://zjuwhw.github.io/" target="blank">zjuwhw</a>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="inferences-in-regeression-and-correlation-analysis" class="section level1">
<h1><span class="header-section-number">3</span> Inferences in Regeression and Correlation Analysis</h1>
<div id="inferences-concerning-beta_1" class="section level2">
<h2><span class="header-section-number">3.1</span> Inferences Concerning <span class="math inline">\(\beta_{1}\)</span></h2>
<ul>
<li>Sampling Distribution of b1</li>
</ul>
<p>The sampling distribution of b1 refers to the different values of b1 that would be obtained with repeated sampling when the levels of the predictor variable X are held constant from sample to sample.</p>
<p>For normal error regression model, the sample distributon of b1 is <strong>normal</strong>, with mean and variance:</p>
<p><span class="math display">\[E(b_1) = \beta_{1}\]</span></p>
<p><span class="math display">\[\sigma^{2}(b_1) = \frac{\sigma^{2}}{\sum(X_{i} - \bar{X})^{2}}\]</span></p>
<ul>
<li>Proof</li>
</ul>
<p>b1 as linear combination of the Yi</p>
<p><span class="math display">\[b1 = \sum k_{i}Y_{i}\text{ where }k_{i} = \frac{X_{i} - \bar{X}}{\sum(X_{i} - \bar{X})^{2}}\]</span> - Nomaily</p>
<p>The <span class="math inline">\(Y_{i}\)</span> are independently, normally distributed, so b1 are normally distributed.</p>
<ul>
<li>Mean</li>
</ul>
<p><span class="math display">\[E(b_{1}) = E(\sum k_{i}Y_{i}) = \sum k_{i}E(Y_{i}) = \sum k_{i}(\beta_{0} + \beta_{1}X_{i}) = \beta_{1}\]</span></p>
<p>hint:</p>
<p><span class="math display">\[\sum k_{i} = 0\]</span></p>
<p><span class="math display">\[\sum k_{i}X_{i} = 1\]</span></p>
<ul>
<li>Variance</li>
</ul>
<p><span class="math display">\[\sigma^{2}(b_{1}) = \sigma^{2}(\sum k_{i}Y_{i}) = \sum k_{i}^{2}\sigma^{2}(Y_{i}) = \sum k_{i}^{2}\sigma^{2} = \sigma^{2}\frac{1}{\sum (X_{i} - \bar{X})^{2}}\]</span></p>
<ul>
<li>Estimated Variance</li>
</ul>
<p>Replace the paramter <span class="math inline">\(\sigma^{2}\)</span> with MSE:</p>
<p><span class="math display">\[s^{2}(b_{1}) = \frac{MSE}{\sum(X_{i} - \bar{X})^{2}}\]</span></p>
<ul>
<li>Sampling Distribution of <span class="math inline">\((b_{1} - \beta_{1})/s(b_{1})\)</span></li>
</ul>
<p><span class="math display">\[(b_{1} - \beta_{1})/\sigma(b_{1}) \sim N(0,1)\]</span></p>
<p><span class="math display">\[(b_{1} - \beta_{1})/s(b_{1}) \sim t(n-2)\]</span></p>
<p>When a statistic is standardized but the denominator is an estimated standard deviation rather than the true standard deviation, it is called a studentized statistic.</p>
<ul>
<li>Comment</li>
</ul>
<p><span class="math display">\[SSE/\sigma^{2} \sim \chi^{2}(n - 2)\]</span></p>
<p><span class="math display">\[(b_{1} - \beta_{1})/s(b_{1}) \sim \frac{z}{\sqrt{\frac{\chi^2(n-2)}{n-2}}} = t(n-2)\]</span></p>
<ul>
<li>Confidence Interval for <span class="math inline">\(\beta_{1}\)</span></li>
</ul>
<p><span class="math display">\[b_{1} \pm t(1-\alpha/2; n-2)s(b_{1})\text{ where }\alpha\text{ is significance level}\]</span></p>
<ul>
<li>Tests concerning <span class="math inline">\(\beta_{1}\)</span></li>
</ul>
<p>Since <span class="math inline">\((b_{1} - \beta_{1})/s(b_{1})\)</span> is ditributed as t with n - 2degrees of freedom, tests concerning <span class="math inline">\(\beta_{1}\)</span> can be set up in ordinary fashion using the t distribution.</p>
</div>
<div id="inferences-concerning-beta_0" class="section level2">
<h2><span class="header-section-number">3.2</span> Inferences Concerning <span class="math inline">\(\beta_{0}\)</span></h2>
<p>The sampling distribution of <span class="math inline">\(\beta_{0}\)</span> is normal, with mean and variance:</p>
<p><span class="math display">\[E(b_{0}) = \beta_{0}\]</span></p>
<p><span class="math display">\[\sigma^{2}(b_{0}) = \sigma^{2}[\frac{1}{n} + \frac{\bar{X}^{2}}{\sum (X_{i} - \bar{X})^{2}}]\]</span></p>
<p><span class="math display">\[s^{2}(b_{0}) = MSE[\frac{1}{n} + \frac{\bar{X}^{2}}{\sum (X_{i} - \bar{X})^{2}}]\]</span></p>
<p><span class="math display">\[\frac{b_{0} - \beta_{0}}{s(b_{0})} \sim t(n-2)\]</span></p>
</div>
<div id="some-considerations-on-making-inferences-concerning-beta_0-and-beta_1" class="section level2">
<h2><span class="header-section-number">3.3</span> Some Considerations on Making Inferences Concerning <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span></h2>
<ul>
<li>Effects of Departures from Normality</li>
<li>Interpretation of Confidence Coefficient and Risks of Errors</li>
<li>Spacing of the X levels</li>
<li>Power of Tests</li>
</ul>
<p>The power of this test is the probability that the decision rule will lead to conclusion <span class="math inline">\(H_{a}\)</span> when <span class="math inline">\(H_{a}\)</span> in fact holds. Specifically, the power is given by</p>
<p><span class="math display">\[Power = P(|t^{*}| &gt; t(1-\alpha/2;n-2)|\delta)\]</span></p>
<p>where,</p>
<ul>
<li><span class="math inline">\(H_{0}: \beta_{1} = \beta_{10}\)</span>; <span class="math inline">\(H_{a}: \beta_{1} \neq \beta_{10}\)</span></li>
<li><span class="math inline">\(t^{*} = \frac{b_{1} - \beta_{10}}{s(b_{1})}\)</span></li>
<li><span class="math inline">\(\delta\)</span> is the <strong>noncentrality measure</strong>, a measure of how far the true value of <span class="math inline">\(\beta_{1}\)</span> is from <span class="math inline">\(\beta_{10}\)</span>. <span class="math inline">\(\delta = \frac{\mid\beta_{1} - \beta_{10}\mid}{\sigma(b_{1})}\)</span></li>
</ul>
</div>
<div id="interval-estimation-of-ey_h" class="section level2">
<h2><span class="header-section-number">3.4</span> Interval Estimation of <span class="math inline">\(E(Y_{h})\)</span></h2>
<p>The mean response when <span class="math inline">\(X = X_{h}\)</span> is denoted by <span class="math inline">\(E(Y_{h})\)</span>. The <span class="math inline">\(E(Y_{h})\)</span> point estimator <span class="math inline">\(\hat{Y}_{h}\)</span> :</p>
<p><span class="math display">\[\hat{Y}_{h} = b_{0} + b_{1}X_{h}\]</span></p>
<ul>
<li>Sampling Distribution of <span class="math inline">\(\hat{Y}_{h}\)</span></li>
</ul>
<p>For normal error regression model, the sampling distribution of <span class="math inline">\(\hat{Y}_{h}\)</span> is normal, with mean and variance:</p>
<p><span class="math display">\[E(\hat{Y}_{h}) = E(Y_{h})\]</span></p>
<p><span class="math display">\[\sigma^{2}(\hat{Y}_{h}) = \sigma^{2}[\frac{1}{n} + \frac{(X_{h} - \bar{X})^2}{\sum(X_{i} - \bar{X})^{2}}]\]</span></p>
<p><span class="math display">\[s^{2}(\hat{Y}_{h}) = MSE[\frac{1}{n} + \frac{(X_{h} - \bar{X})^{2}}{\sum (X_{i} - \bar{X})^{2}}]\]</span></p>
<p><span class="math display">\[\frac{\hat{Y}_{h} - E(Y_{h})}{s(\hat{Y}_{h})} \sim t(n-2)\]</span></p>
</div>
<div id="prediction-of-new-observation" class="section level2">
<h2><span class="header-section-number">3.5</span> Prediction of New Observation</h2>
<p>We denote the level of X for the new trial as <span class="math inline">\(X_{h}\)</span> and the new observation on Y as <span class="math inline">\(Y_{h(new)}\)</span>.</p>
<p>In the former case, the estimation of <span class="math inline">\(E(Y_{h})\)</span> is the <strong>mean</strong> of the distribution of Y; in the present case, we predict an <strong>individual outcome</strong> draw from the distribution of Y.</p>
<p>Hence, two components of <span class="math inline">\(\sigma(pred)\)</span>:</p>
<ol style="list-style-type: decimal">
<li>The variance of the distribution of Y at <span class="math inline">\(X = X_{h}\)</span>, namely <span class="math inline">\(\sigma^{2}\)</span></li>
<li>The variance of the sampling distribution of <span class="math inline">\(\hat{Y}_h\)</span>, namely <span class="math inline">\(\sigma^{2}(\hat{Y}_h)\)</span></li>
</ol>
<p><span class="math display">\[\sigma^{2}(pred) = \sigma^{2}(Y_{h(new)} - \hat{Y}_{h}) = \sigma^{2} + \sigma^{2}(\hat{Y}_{h})\]</span></p>
<p><span class="math display">\[s^{2}(pred) = MSE[1 + \frac{1}{n} + \frac{(X_{h} - \bar{X})^{2}}{\sum (X_{i} - \bar{X})^{2}}]\]</span></p>
</div>
<div id="confidence-band-for-regression-line" class="section level2">
<h2><span class="header-section-number">3.6</span> Confidence Band for Regression Line</h2>
<p>To obtain a confidence band for the entire for the entire regression line <span class="math inline">\(E(Y) = \beta_{0} + \beta_{1}X\)</span>.</p>
<p>The <strong>Working-Hotellling</strong> 1 - <span class="math inline">\(\alpha\)</span> confidence band:</p>
<p><span class="math display">\[\hat{Y}_{h} \pm Ws(\hat{Y}_{h})\]</span></p>
<p>where,</p>
<p><span class="math display">\[W^{2} = 2F(1-\alpha; 2, n-2)\]</span></p>
<p>Since, we are doing all values of <span class="math inline">\(X_{h}\)</span> at once, it will be wider at each <span class="math inline">\(X_{h}\)</span> than CIs for individual <span class="math inline">\(X_{h}\)</span>.</p>
</div>
<div id="analysis-of-variance-approach" class="section level2">
<h2><span class="header-section-number">3.7</span> Analysis of Variance Approach</h2>
<ul>
<li>Partitioning of Total Sum of Squares</li>
</ul>
<p><span class="math display">\[Y_{i} - \bar{Y} = \hat{Y}_{i} - \bar{Y} + Y_{i} - \hat{Y}_{i}\]</span></p>
<p><span class="math display">\[\sum (Y_{i} - \bar{Y})^{2} = \sum (\hat{Y}_{i} - \bar{Y})^{2} + \sum (Y_{i} - \hat{Y}_{i})^{2}\]</span></p>
<p><span class="math display">\[SSTO = SSR + SSE\]</span></p>
<p>SSTO stands for <strong>total sum of squares</strong>, SSE stands for <strong>error sum of squares</strong> and SSR stands for <strong>regression sum of squares</strong>.</p>
<ul>
<li>Breakdown of Degrees of Freedom</li>
</ul>
<p><span class="math display">\[n - 1 = 1 + (n - 2)\]</span></p>
<p>We have n-1 degrees of freedom associated with SSTO. SSE has n-2 degrees of freedom and SSR has 1 degree of freedom.</p>
<ul>
<li>Mean Squares</li>
</ul>
<p>A sum of squares divided by its associated degrees of freedom is called a <strong>mean square</strong> (MS)</p>
<p>The mean squares are not additive:</p>
<p><span class="math inline">\(\frac{SSTO}{n-1} \neq \frac{SSR}{1} + \frac{SSE}{n-2} = MSR + MSE\)</span></p>
<ul>
<li>ANalysis Of VAriance Table (ANOVA table)</li>
</ul>
<p><strong>ANOVA table</strong>: The breakdowns of the total sum of squares and associated degrees of freedom are displayed in the form of ANVOA.</p>
<p><strong>SSTOU</strong>: the total uncorrected sum of squares, <span class="math inline">\(\sum Y_i^2\)</span></p>
<p><strong>SS</strong>: correction for the mean sum of squares, <span class="math inline">\(n\bar{Y}^2\)</span></p>
<p><strong>SSTO</strong> = <span class="math inline">\(\sum (Y_i - \bar{Y})^2 = \sum Y_i^2 - n\bar{Y}^2 = SSTOU + SS\)</span></p>
<table>
<thead>
<tr class="header">
<th align="left">Source of Variation</th>
<th align="left">SS</th>
<th align="left">df</th>
<th align="left">MS</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Regression</td>
<td align="left"><span class="math inline">\(SSR = \sum(\hat{Y}_i - \bar{Y})^2\)</span></td>
<td align="left">1</td>
<td align="left"><span class="math inline">\(MSR = \frac{SSR}{1}\)</span></td>
</tr>
<tr class="even">
<td align="left">Error</td>
<td align="left"><span class="math inline">\(SSE = \sum(Y_i - \hat{Y}_i)^2\)</span></td>
<td align="left">n-2</td>
<td align="left"><span class="math inline">\(MSE = \frac{SSE}{n-2}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Total</td>
<td align="left"><span class="math inline">\(SSTO = \sum(Y_i - \bar{Y})^2\)</span></td>
<td align="left">n-1</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Correction for mean</td>
<td align="left"><span class="math inline">\(SS \text{(correction for mean)} = n\bar{Y}^2\)</span></td>
<td align="left">1</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Total, uncorrected</td>
<td align="left"><span class="math inline">\(SSTOU = \sum Y_i^2\)</span></td>
<td align="left">n</td>
<td align="left"></td>
</tr>
</tbody>
</table>
<ul>
<li>Expected Mean Squares</li>
</ul>
<p><span class="math display">\[E(MSE) = \sigma^2\]</span></p>
<p><span class="math display">\[E(MSR) = \sigma^2 + \beta_1^2 \sum (X_i - \bar{X})^2\]</span></p>
<ul>
<li>F test for <span class="math inline">\(\beta_1 = 0\)</span> versus <span class="math inline">\(\beta_1 \neq 0\)</span></li>
</ul>
<p>Test Statistic: <span class="math inline">\(F^* = \frac{MSR}{MSE} \sim F(1,n-2)\)</span></p>
</div>
<div id="general-linear-test-approach" class="section level2">
<h2><span class="header-section-number">3.8</span> General Linear Test Approach</h2>
<ul>
<li>Two models:
<ul>
<li><span class="math inline">\(Y_i = \beta_0 + \beta_2X_i + \varepsilon_i\)</span> (full model)</li>
<li><span class="math inline">\(Y_i = \beta_0 + \varepsilon_i\)</span> (reduced model under H0)</li>
</ul></li>
<li>F-statistic:</li>
</ul>
<p><span class="math display">\[F = \frac{(SSE(R) - SSE(F))/(df_R - df_F)}{SSE(F)/df_F}\]</span></p>
<p>The general linear teest approach can be used for highly complex tests of linear statistical models, as well as for simple tests. The basic steps in summary form are:</p>
<ol style="list-style-type: decimal">
<li>Fit the full model and obtain the error sum of squares SSE(F)</li>
<li>Fit the reduced model under H0 and obtain the error sum of squares SSE(R)</li>
<li>Use the test statistic and desicison rule</li>
</ol>
</div>
<div id="descriptive-measures-of-linear-association-between-x-and-y" class="section level2">
<h2><span class="header-section-number">3.9</span> Descriptive Measures of Linear Association between X and Y</h2>
<ul>
<li>Coefficient of Determination</li>
</ul>
<p><span class="math display">\[R^2 = \frac{SSR}{SSTO} = 1 - \frac{SSE}{SSTO}, 0 \leq R^2 \leq 1\]</span></p>
<ul>
<li>Limitations of <span class="math inline">\(R^2\)</span></li>
</ul>
<p>Tree common misunderstandings about <span class="math inline">\(R^2\)</span></p>
<ol style="list-style-type: decimal">
<li>A high coefficient of determination indicates that useful predictions can be made.</li>
<li>A high coefficient of determination indicates that the estimated regression line is a good fit.</li>
<li>A coefficient of determination near zero indicates that X and Y are not related.</li>
</ol>
<ul>
<li>Coefficient of Correlation</li>
</ul>
<p><span class="math display">\[r = \pm \sqrt{R^2}, -1 \leq r \leq 1\]</span></p>
</div>
<div id="considerations-in-applying-regression-analysis" class="section level2">
<h2><span class="header-section-number">3.10</span> Considerations in Applying Regression Analysis</h2>
<ol style="list-style-type: decimal">
<li>make inferences</li>
<li>the predictor variable itsef often has to be predicted</li>
<li>the levels of the predictor variable that fall outside the range of observations</li>
<li><span class="math inline">\(\beta_1 \neq 0\)</span> doesnot establish a cause-and-effect relation</li>
<li>multiple testing</li>
<li>observations on the predictor variable X are subject to measurement erros</li>
</ol>
</div>
<div id="normal-correlation-models" class="section level2">
<h2><span class="header-section-number">3.11</span> Normal Correlation Models</h2>
<ul>
<li>Distinction between Regression and Correlation Model</li>
<li>Bivariate Normal Distribution</li>
<li>Conditional Inferences</li>
<li>Inferences on Correlation Coefficients</li>
<li>Spearman Rank Correlation Coefficient</li>
</ul>
</div>
<div id="r-code" class="section level2">
<h2><span class="header-section-number">3.12</span> R code</h2>
<div id="example-data" class="section level3">
<h3><span class="header-section-number">3.12.1</span> Example data</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(trees)</code></pre></div>
<pre><code>##   Girth Height Volume
## 1   8.3     70   10.3
## 2   8.6     65   10.3
## 3   8.8     63   10.2
## 4  10.5     72   16.4
## 5  10.7     81   18.8
## 6  10.8     83   19.7</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">X =<span class="st"> </span>trees<span class="op">$</span>Volume ## 体积
Y =<span class="st"> </span>trees<span class="op">$</span>Girth ## 直径</code></pre></div>
</div>
<div id="built-in-function" class="section level3">
<h3><span class="header-section-number">3.12.2</span> built-in function</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit &lt;-<span class="st"> </span><span class="kw">lm</span>(Y<span class="op">~</span>X)
<span class="kw">summary</span>(fit)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Y ~ X)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.2945 -0.5742 -0.1520  0.7131  1.5248 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 7.677857   0.308628   24.88   &lt;2e-16 ***
## X           0.184632   0.009016   20.48   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.8117 on 29 degrees of freedom
## Multiple R-squared:  0.9353, Adjusted R-squared:  0.9331 
## F-statistic: 419.4 on 1 and 29 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coefficients</span>(fit) <span class="co"># model coefficients</span></code></pre></div>
<pre><code>## (Intercept)           X 
##   7.6778570   0.1846321</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(fit, <span class="dt">level=</span><span class="fl">0.95</span>) <span class="co"># CIs for model parameters </span></code></pre></div>
<pre><code>##                 2.5 %    97.5 %
## (Intercept) 7.0466415 8.3090724
## X           0.1661924 0.2030719</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">fitted</span>(fit) <span class="co"># predicted values</span></code></pre></div>
<pre><code>##         1         2         3         4         5         6         7 
##  9.579568  9.579568  9.561105 10.705824 11.148941 11.315110 10.558118 
##         8         9        10        11        12        13        14 
## 11.038162 11.850543 11.352036 12.145955 11.555132 11.628985 11.610521 
##        15        16        17        18        19        20        21 
## 11.204331 11.776690 13.918423 12.736777 12.422903 12.275197 14.047666 
##        22        23        24        25        26        27        28 
## 13.530696 14.380003 14.749268 15.543186 17.906477 17.961867 18.441910 
##        29        30        31 
## 17.186412 17.094096 21.894531</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">residuals</span>(fit) <span class="co"># residuals</span></code></pre></div>
<pre><code>##           1           2           3           4           5           6 
## -1.27956795 -0.97956795 -0.76110474 -0.20582396 -0.44894108 -0.51511000 
##           7           8           9          10          11          12 
##  0.44188174 -0.03816180 -0.75054318 -0.15203642 -0.84595459 -0.15513177 
##          13          14          15          16          17          18 
## -0.22898462  0.08947859  0.79566928  1.12330967 -1.01842306  0.56322259 
##          19          20          21          22          23          24 
##  1.27709721  1.52480292 -0.04766555  0.66930442  0.11999661  1.25073235 
##          25          26          27          28          29          30 
##  0.75681418 -0.60647711 -0.46186675 -0.54191030  0.81358820  0.90590427 
##          31 
## -1.29453117</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(fit) <span class="co"># anova table </span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: Y
##           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    
## X          1 276.328 276.328  419.36 &lt; 2.2e-16 ***
## Residuals 29  19.109   0.659                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="point-estimator-b_0-and-b_1" class="section level3">
<h3><span class="header-section-number">3.12.3</span> point estimator <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span></h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n =<span class="st"> </span><span class="kw">nrow</span>(trees)
Xbar =<span class="st"> </span><span class="kw">mean</span>(X)
Ybar =<span class="st"> </span><span class="kw">mean</span>(Y)
b1 =<span class="st"> </span><span class="kw">sum</span>((X <span class="op">-</span><span class="st"> </span>Xbar)<span class="op">*</span>(Y <span class="op">-</span><span class="st"> </span>Ybar))<span class="op">/</span><span class="kw">sum</span>((X<span class="op">-</span>Xbar)<span class="op">^</span><span class="dv">2</span>)
b0 =<span class="st"> </span>Ybar <span class="op">-</span><span class="st"> </span>b1<span class="op">*</span>Xbar
b1;b0</code></pre></div>
<pre><code>## [1] 0.1846321</code></pre>
<pre><code>## [1] 7.677857</code></pre>
</div>
<div id="residuals-sse-and-mse" class="section level3">
<h3><span class="header-section-number">3.12.4</span> Residuals, SSE and MSE</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">residual =<span class="st"> </span>Y <span class="op">-</span><span class="st"> </span>b1<span class="op">*</span>X <span class="op">-</span><span class="st"> </span>b0
SSE =<span class="st"> </span><span class="kw">sum</span>(residual<span class="op">^</span><span class="dv">2</span>)
MSE =<span class="st"> </span>SSE<span class="op">/</span>(n<span class="op">-</span><span class="dv">2</span>)
SSE; MSE; <span class="kw">sqrt</span>(MSE)</code></pre></div>
<pre><code>## [1] 19.10893</code></pre>
<pre><code>## [1] 0.6589286</code></pre>
<pre><code>## [1] 0.8117442</code></pre>
</div>
<div id="sampling-distribution-of-b_1-and-b_1beta_1sb_1" class="section level3">
<h3><span class="header-section-number">3.12.5</span> sampling distribution of <span class="math inline">\(b_1\)</span> and <span class="math inline">\((b_1−\beta_1)/s(b_1)\)</span></h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">s =<span class="st"> </span><span class="kw">sqrt</span>( MSE<span class="op">/</span><span class="kw">sum</span>((X <span class="op">-</span><span class="st"> </span>Xbar)<span class="op">^</span><span class="dv">2</span>))
t =<span class="st"> </span>b1 <span class="op">/</span><span class="st"> </span>s
p =<span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pt</span>(t, n <span class="op">-</span><span class="dv">2</span>))<span class="op">*</span><span class="dv">2</span>
s; t; p</code></pre></div>
<pre><code>## [1] 0.009015995</code></pre>
<pre><code>## [1] 20.47829</code></pre>
<pre><code>## [1] 0</code></pre>
</div>
<div id="f-test" class="section level3">
<h3><span class="header-section-number">3.12.6</span> F test</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">SSTO =<span class="st"> </span><span class="kw">var</span>(Y) <span class="op">*</span><span class="st"> </span>(n<span class="op">-</span><span class="dv">1</span>)
F =<span class="st"> </span>(SSTO <span class="op">-</span><span class="st"> </span>SSE)<span class="op">/</span>((n<span class="op">-</span><span class="dv">1</span>) <span class="op">-</span><span class="st"> </span>(n<span class="op">-</span><span class="dv">2</span>)) <span class="op">/</span><span class="st"> </span>(SSE<span class="op">/</span>(n<span class="op">-</span><span class="dv">2</span>))
F</code></pre></div>
<pre><code>## [1] 419.3603</code></pre>
</div>
<div id="r2-and-r" class="section level3">
<h3><span class="header-section-number">3.12.7</span> <span class="math inline">\(R^2\)</span> and r</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Rsq =<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>SSE<span class="op">/</span>SSTO
r =<span class="st"> </span>b1<span class="op">/</span><span class="kw">abs</span>(b1) <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(Rsq) 
Rsq; r; <span class="kw">cor</span>(X,Y)</code></pre></div>
<pre><code>## [1] 0.9353199</code></pre>
<pre><code>## [1] 0.9671194</code></pre>
<pre><code>## [1] 0.9671194</code></pre>
</div>
<div id="plot" class="section level3">
<h3><span class="header-section-number">3.12.8</span> plot</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(X,Y)
<span class="kw">abline</span>(b0,b1, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="linear-regression-with-one-predictor-variable.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="diagnostics-and-remedial-measures.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
