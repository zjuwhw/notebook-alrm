<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title></title>
  <meta name="description" content="">
  <meta name="generator" content="bookdown 0.4 and GitBook 2.6.7">

  <meta property="og:title" content="" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="linear-regression-with-one-predictor-variable.html">
<link rel="next" href="diagnostics-and-remedial-measures.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Notebook for ALRM</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a></li>
<li class="chapter" data-level="2" data-path="linear-regression-with-one-predictor-variable.html"><a href="linear-regression-with-one-predictor-variable.html"><i class="fa fa-check"></i><b>2</b> Linear regression with one predictor variable</a><ul>
<li class="chapter" data-level="2.1" data-path="linear-regression-with-one-predictor-variable.html"><a href="linear-regression-with-one-predictor-variable.html#relations-between-variables"><i class="fa fa-check"></i><b>2.1</b> Relations between variables</a></li>
<li class="chapter" data-level="2.2" data-path="linear-regression-with-one-predictor-variable.html"><a href="linear-regression-with-one-predictor-variable.html#regression-models-and-their-uses"><i class="fa fa-check"></i><b>2.2</b> Regression Models and Their Uses</a></li>
<li class="chapter" data-level="2.3" data-path="linear-regression-with-one-predictor-variable.html"><a href="linear-regression-with-one-predictor-variable.html#simple-linear-regression-model-with-distribution-of-error-terms-unspecified"><i class="fa fa-check"></i><b>2.3</b> Simple linear regression model with distribution of error terms unspecified</a></li>
<li class="chapter" data-level="2.4" data-path="linear-regression-with-one-predictor-variable.html"><a href="linear-regression-with-one-predictor-variable.html#data-for-regression-analysis"><i class="fa fa-check"></i><b>2.4</b> Data for regression analysis</a></li>
<li class="chapter" data-level="2.5" data-path="linear-regression-with-one-predictor-variable.html"><a href="linear-regression-with-one-predictor-variable.html#overview-of-steps-in-regression-analysis"><i class="fa fa-check"></i><b>2.5</b> Overview of steps in regression analysis</a></li>
<li class="chapter" data-level="2.6" data-path="linear-regression-with-one-predictor-variable.html"><a href="linear-regression-with-one-predictor-variable.html#estimation-of-regression-function"><i class="fa fa-check"></i><b>2.6</b> Estimation of regression function</a></li>
<li class="chapter" data-level="2.7" data-path="linear-regression-with-one-predictor-variable.html"><a href="linear-regression-with-one-predictor-variable.html#estimation-of-erro-terms-variance-sigma2"><i class="fa fa-check"></i><b>2.7</b> Estimation of Erro Terms Variance <span class="math inline">\(\sigma^{2}\)</span></a></li>
<li class="chapter" data-level="2.8" data-path="linear-regression-with-one-predictor-variable.html"><a href="linear-regression-with-one-predictor-variable.html#normal-error-regression-model"><i class="fa fa-check"></i><b>2.8</b> Normal Error Regression Model</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html"><i class="fa fa-check"></i><b>3</b> Inferences in Regeression and Correlation Analysis</a><ul>
<li class="chapter" data-level="3.1" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#inferences-concerning-beta_1"><i class="fa fa-check"></i><b>3.1</b> Inferences Concerning <span class="math inline">\(\beta_{1}\)</span></a></li>
<li class="chapter" data-level="3.2" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#inferences-concerning-beta_0"><i class="fa fa-check"></i><b>3.2</b> Inferences Concerning <span class="math inline">\(\beta_{0}\)</span></a></li>
<li class="chapter" data-level="3.3" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#some-considerations-on-making-inferences-concerning-beta_0-and-beta_1"><i class="fa fa-check"></i><b>3.3</b> Some Considerations on Making Inferences Concerning <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span></a></li>
<li class="chapter" data-level="3.4" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#interval-estimation-of-ey_h"><i class="fa fa-check"></i><b>3.4</b> Interval Estimation of <span class="math inline">\(E(Y_{h})\)</span></a></li>
<li class="chapter" data-level="3.5" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#prediction-of-new-observation"><i class="fa fa-check"></i><b>3.5</b> Prediction of New Observation</a></li>
<li class="chapter" data-level="3.6" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#confidence-band-for-regression-line"><i class="fa fa-check"></i><b>3.6</b> Confidence Band for Regression Line</a></li>
<li class="chapter" data-level="3.7" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#analysis-of-variance-approach"><i class="fa fa-check"></i><b>3.7</b> Analysis of Variance Approach</a></li>
<li class="chapter" data-level="3.8" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#general-linear-test-approach"><i class="fa fa-check"></i><b>3.8</b> General Linear Test Approach</a></li>
<li class="chapter" data-level="3.9" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#descriptive-measures-of-linear-association-between-x-and-y"><i class="fa fa-check"></i><b>3.9</b> Descriptive Measures of Linear Association between X and Y</a></li>
<li class="chapter" data-level="3.10" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#considerations-in-applying-regression-analysis"><i class="fa fa-check"></i><b>3.10</b> Considerations in Applying Regression Analysis</a></li>
<li class="chapter" data-level="3.11" data-path="inferences-in-regeression-and-correlation-analysis.html"><a href="inferences-in-regeression-and-correlation-analysis.html#normal-correlation-models"><i class="fa fa-check"></i><b>3.11</b> Normal Correlation Models</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="diagnostics-and-remedial-measures.html"><a href="diagnostics-and-remedial-measures.html"><i class="fa fa-check"></i><b>4</b> Diagnostics and Remedial Measures</a></li>
<li class="chapter" data-level="5" data-path="simultaneous-inferences-and-other-topics-in-regression-analysis.html"><a href="simultaneous-inferences-and-other-topics-in-regression-analysis.html"><i class="fa fa-check"></i><b>5</b> Simultaneous Inferences and Other Topics in Regression Analysis</a></li>
<li class="chapter" data-level="6" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html"><i class="fa fa-check"></i><b>6</b> Matrix Approach to Simple Linear Regression Analysis</a><ul>
<li class="chapter" data-level="6.1" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#matrices"><i class="fa fa-check"></i><b>6.1</b> Matrices</a></li>
<li class="chapter" data-level="6.2" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#matrix-addition-and-subtraction"><i class="fa fa-check"></i><b>6.2</b> Matrix Addition and Subtraction</a></li>
<li class="chapter" data-level="6.3" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#matrix-multiplication"><i class="fa fa-check"></i><b>6.3</b> Matrix Multiplication</a></li>
<li class="chapter" data-level="6.4" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#special-types-of-matrices"><i class="fa fa-check"></i><b>6.4</b> Special Types of Matrices</a></li>
<li class="chapter" data-level="6.5" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#linear-dependence-and-rank-of-matrix"><i class="fa fa-check"></i><b>6.5</b> Linear Dependence and Rank of Matrix</a></li>
<li class="chapter" data-level="6.6" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#inverse-of-a-matrix"><i class="fa fa-check"></i><b>6.6</b> Inverse of a Matrix</a></li>
<li class="chapter" data-level="6.7" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#some-basic-results-for-matrics"><i class="fa fa-check"></i><b>6.7</b> Some Basic Results for Matrics</a></li>
<li class="chapter" data-level="6.8" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#random-vectors-and-matrices"><i class="fa fa-check"></i><b>6.8</b> Random Vectors and Matrices</a></li>
<li class="chapter" data-level="6.9" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#simple-linear-regression-model-in-matrix-terms"><i class="fa fa-check"></i><b>6.9</b> Simple Linear Regression Model in Matrix Terms</a></li>
<li class="chapter" data-level="6.10" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#leasst-squares-estimation-of-regression-parameters"><i class="fa fa-check"></i><b>6.10</b> Leasst Squares Estimation of Regression Parameters</a></li>
<li class="chapter" data-level="6.11" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#fitted-values-and-residuals"><i class="fa fa-check"></i><b>6.11</b> Fitted Values and Residuals</a></li>
<li class="chapter" data-level="6.12" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#analysis-of-variance-results"><i class="fa fa-check"></i><b>6.12</b> Analysis of Variance Results</a></li>
<li class="chapter" data-level="6.13" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#inferences-in-regeression-analysis"><i class="fa fa-check"></i><b>6.13</b> Inferences in Regeression Analysis</a></li>
<li class="chapter" data-level="6.14" data-path="matrix-approach-to-simple-linear-regression-analysis.html"><a href="matrix-approach-to-simple-linear-regression-analysis.html#r-code"><i class="fa fa-check"></i><b>6.14</b> R code</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="multiple-linear-regression-i.html"><a href="multiple-linear-regression-i.html"><i class="fa fa-check"></i><b>7</b> Multiple linear regression I</a><ul>
<li class="chapter" data-level="7.1" data-path="multiple-linear-regression-i.html"><a href="multiple-linear-regression-i.html#multiple-regression-models"><i class="fa fa-check"></i><b>7.1</b> Multiple Regression Models</a><ul>
<li class="chapter" data-level="7.1.1" data-path="multiple-linear-regression-i.html"><a href="multiple-linear-regression-i.html#first-order-model-with-two-predictor-variables"><i class="fa fa-check"></i><b>7.1.1</b> First-Order Model with Two Predictor Variables</a></li>
<li class="chapter" data-level="7.1.2" data-path="multiple-linear-regression-i.html"><a href="multiple-linear-regression-i.html#first-order-model-with-more-than-two-predictor-variables"><i class="fa fa-check"></i><b>7.1.2</b> First-Order Model with More than Two Predictor Variables</a></li>
<li class="chapter" data-level="7.1.3" data-path="multiple-linear-regression-i.html"><a href="multiple-linear-regression-i.html#general-linear-regression-model"><i class="fa fa-check"></i><b>7.1.3</b> General Linear Regression Model</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="multiple-linear-regression-i.html"><a href="multiple-linear-regression-i.html#general-linear-regression-model-in-matrix-terms"><i class="fa fa-check"></i><b>7.2</b> General Linear Regression Model in Matrix Terms</a></li>
<li class="chapter" data-level="7.3" data-path="multiple-linear-regression-i.html"><a href="multiple-linear-regression-i.html#estimation-of-regression-coefficients"><i class="fa fa-check"></i><b>7.3</b> Estimation of Regression Coefficients</a></li>
</ul></li>
<li class="divider"></li>
Published with <a href="https://github.com/rstudio/bookdown" target="blank">bookdown</a> by <a href="http://zjuwhw.github.io/" target="blank">zjuwhw</a>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="inferences-in-regeression-and-correlation-analysis" class="section level1">
<h1><span class="header-section-number">3</span> Inferences in Regeression and Correlation Analysis</h1>
<div id="inferences-concerning-beta_1" class="section level2">
<h2><span class="header-section-number">3.1</span> Inferences Concerning <span class="math inline">\(\beta_{1}\)</span></h2>
<ul>
<li>Sampling Distribution of b1</li>
</ul>
<p>The sampling distribution of b1 refers to the different values of b1 that would be obtained with repeated sampling when the levels of the predictor variable X are held constant from sample to sample.</p>
<p>For normal error regression model, the sample distributon of b1 is <strong>normal</strong>, with mean and variance:</p>
<p><span class="math display">\[E(b1) = \beta_{1}\]</span></p>
<p><span class="math display">\[\sigma^{2}(b1) = \frac{\sigma^{2}}{\sum(X_{i} - \bar{X})^{2}}\]</span></p>
<ul>
<li>Proof</li>
</ul>
<p>b1 as linear combination of the Yi</p>
<p><span class="math display">\[b1 = \sum k_{i}Y_{i}\text{where }k_{i} = \frac{X_{i} - \bar{X}}{\sum(X_{i} - \bar{X})^{2}}\]</span> ( - Nomaily</p>
<p>The <span class="math inline">\(Y_{i}\)</span> are independently, normally distributed, so b1 are normally distributed.</p>
<ul>
<li>Mean</li>
</ul>
<p><span class="math display">\[E(b_{1}) = E(\sum k_{i}Y_{i}) = \sum k_{i}E(Y_{i}) = \sum k_{i}(\beta_{0} + \beta_{1}X_{i}) = \beta_{1}\]</span></p>
<p>hint:</p>
<p><span class="math display">\[\sum k_{i} = 0\]</span></p>
<p><span class="math display">\[\sum k_{i}X_{i} = 1\]</span></p>
<ul>
<li>Variance</li>
</ul>
<p><span class="math display">\[\sigma^{2}(b_{1}) = \sigma^{2}(\sum k_{i}Y_{i}) = \sum k_{i}^{2}\sigma^{2}(Y_{i}) = \sum k_{i}^{2}\sigma^{2} = \sigma^{2}\frac{1}{\sum (X_{i} - \bar{X})^{2}}\]</span></p>
<ul>
<li>Estimated Variance</li>
</ul>
<p>Replace the paramter <span class="math inline">\(\sigma^{2}\)</span> with MSE:</p>
<p><span class="math display">\[s^{2}(b_{1}) = \frac{MSE}{\sum(X_{i} - \bar{X})^{2}}\]</span></p>
<ul>
<li>Sampling Distribution of <span class="math inline">\((b_{1} - \beta_{1})/s(b_{1})\)</span></li>
</ul>
<p><span class="math display">\[(b_{1} - \beta_{1})/\sigma(b_{1}) \sim N(0,1)\]</span></p>
<p><span class="math display">\[(b_{1} - \beta_{1})/s(b_{1}) \sim t(n-2)\]</span></p>
<p>When a statistic is standardized but the denominator is an estimated standard deviation rather than the true standard deviation, it is called a studentized statistic.</p>
<ul>
<li>Comment</li>
</ul>
<p><span class="math display">\[SSE/\sigma^{2} \sim \chi^{2}(n - 2)\]</span></p>
<p><span class="math display">\[(b_{1} - \beta_{1})/s(b_{1}) \sim \frac{z}{\sqrt{\frac{\chi^2(n-2)}{n-2}}} = t(n-2)\]</span></p>
<ul>
<li>Confidence Interval for <span class="math inline">\(\beta_{1}\)</span></li>
</ul>
<p><span class="math display">\[b_{1} \pm t(1-\alpha/2; n-2)s(b_{1})\text{ where }\alpha\text{ is significance level}\]</span></p>
<ul>
<li>Tests concerning <span class="math inline">\(\beta_{1}\)</span></li>
</ul>
<p>Since <span class="math inline">\((b_{1} - \beta_{1})/s(b_{1})\)</span> is ditributed as t with n - 2degrees of freedom, tests concerning <span class="math inline">\(\beta_{1}\)</span> can be set up in ordinary fashion using the t distribution.</p>
</div>
<div id="inferences-concerning-beta_0" class="section level2">
<h2><span class="header-section-number">3.2</span> Inferences Concerning <span class="math inline">\(\beta_{0}\)</span></h2>
<p>The sampling distribution of <span class="math inline">\(\beta_{0}\)</span> is normal, with mean and variance:</p>
<p><span class="math display">\[E(b_{0}) = \beta_{0}\]</span></p>
<p><span class="math display">\[\sigma^{2}(b_{0}) = \sigma^{2}[\frac{1}{n} + \frac{\bar{X}^{2}}{\sum (X_{i} - \bar{X})^{2}}]\]</span></p>
<p><span class="math display">\[s^{2}(b_{0}) = MSE[\frac{1}{n} + \frac{\bar{X}^{2}}{\sum (X_{i} - \bar{X})^{2}}]\]</span></p>
<p><span class="math display">\[\frac{b_{0} - \beta_{0}}{s(b_{0})} \sim t(n-2)\]</span></p>
</div>
<div id="some-considerations-on-making-inferences-concerning-beta_0-and-beta_1" class="section level2">
<h2><span class="header-section-number">3.3</span> Some Considerations on Making Inferences Concerning <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span></h2>
<ul>
<li>Effects of Departures from Normality</li>
<li>Interpretation of Confidence Coefficient and Risks of Errors</li>
<li>Spacing of the X levels</li>
<li>Power of Tests</li>
</ul>
<p>The power of this test is the probability that the decision rule will lead to conclusion <span class="math inline">\(H_{a}\)</span> when <span class="math inline">\(H_{a}\)</span> in fact holds. Specifically, the power is given by</p>
<p><span class="math display">\[Power = P(|t^{*}| &gt; t(1-\alpha/2;n-2)|\delta)\]</span></p>
<p>where,</p>
<ul>
<li><span class="math inline">\(H_{0}: \beta_{1} = \beta_{10}\)</span>; <span class="math inline">\(H_{a}: \beta_{1} \neq \beta_{10}\)</span></li>
<li><span class="math inline">\(t^{*} = \frac{b_{1} - \beta_{10}}{s(b_{1})}\)</span></li>
<li><span class="math inline">\(\delta\)</span> is the <strong>noncentrality measure</strong>, a measure of how far the true value of <span class="math inline">\(\beta_{1}\)</span> is from <span class="math inline">\(\beta_{10}\)</span>. <span class="math inline">\(\delta = \frac{\mid\beta_{1} - \beta_{10}\mid}{\sigma(b_{1})}\)</span></li>
</ul>
</div>
<div id="interval-estimation-of-ey_h" class="section level2">
<h2><span class="header-section-number">3.4</span> Interval Estimation of <span class="math inline">\(E(Y_{h})\)</span></h2>
<p>The mean response when <span class="math inline">\(X = X_{h}\)</span> is denoted by <span class="math inline">\(E(Y_{h})\)</span>. The <span class="math inline">\(E(Y_{h})\)</span> point estimator <span class="math inline">\(\hat{Y}_{h}\)</span> :</p>
<p><span class="math display">\[\hat{Y}_{h} = b_{0} + b_{1}X_{h}\]</span></p>
<ul>
<li>Sampling Distribution of <span class="math inline">\(\hat{Y}_{h}\)</span></li>
</ul>
<p>For normal error regression model, the sampling distribution of <span class="math inline">\(\hat{Y}_{h}\)</span> is normal, with mean and variance:</p>
<p><span class="math display">\[E(\hat{Y}_{h}) = E(Y_{h})\]</span></p>
<p><span class="math display">\[\sigma^{2}(\hat{Y}_{h}) = \sigma^{2}[\frac{1}{n} + \frac{(X_{h} - \bar{X})^2}{\sum(X_{i} - \bar{X})^{2}}]\]</span></p>
<p><span class="math display">\[s^{2}(\hat{Y}_{h}) = MSE[\frac{1}{n} + \frac{(X_{h} - \bar{X})^{2}}{\sum (X_{i} - \bar{X})^{2}}]\]</span></p>
<p><span class="math display">\[\frac{\hat{Y}_{h} - E(Y_{h})}{s(\hat{Y}_{h})} \sim t(n-2)\]</span></p>
</div>
<div id="prediction-of-new-observation" class="section level2">
<h2><span class="header-section-number">3.5</span> Prediction of New Observation</h2>
<p>We denote the level of X for the new trial as <span class="math inline">\(X_{h}\)</span> and the new observation on Y as <span class="math inline">\(Y_{h(new)}\)</span>.</p>
<p>In the former case, the estimation of <span class="math inline">\(E(Y_{h})\)</span> is the <strong>mean</strong> of the distribution of Y; in the present case, we predict an <strong>individual outcome</strong> draw from the distribution of Y.</p>
<p>Hence, two components of <span class="math inline">\(\sigma(pred)\)</span>:</p>
<ol style="list-style-type: decimal">
<li>The variance of the distribution of Y at <span class="math inline">\(X = X_{h}\)</span>, namely <span class="math inline">\(\sigma^{2}\)</span></li>
<li>The variance of the sampling distribution of <span class="math inline">\(\hat{Y}_h\)</span>, namely <span class="math inline">\(\sigma^{2}(\hat{Y}_h)\)</span></li>
</ol>
<p><span class="math display">\[\sigma^{2}(pred) = \sigma^{2}(Y_{h(new)} - \hat{Y}_{h}) = \sigma^{2} + \sigma^{2}(\hat{Y}_{h})\]</span></p>
<p><span class="math display">\[s^{2}(pred) = MSE[1 + \frac{1}{n} + \frac{(X_{h} - \bar{X})^{2}}{\sum (X_{i} - \bar{X})^{2}}]\]</span></p>
</div>
<div id="confidence-band-for-regression-line" class="section level2">
<h2><span class="header-section-number">3.6</span> Confidence Band for Regression Line</h2>
<p>To obtain a confidence band for the entire for the entire regression line <span class="math inline">\(E(Y) = \beta_{0} + \beta_{1}X\)</span>.</p>
<p>The <strong>Working-Hotellling</strong> 1 - <span class="math inline">\(\alpha\)</span> confidence band:</p>
<p><span class="math display">\[\hat{Y}_{h} \pm Ws(\hat{Y}_{h})\]</span></p>
<p>where,</p>
<p><span class="math display">\[W^{2} = 2F(1-\alpha; 2, n-2)\]</span></p>
<p>Since, we are doing all values of <span class="math inline">\(X_{h}\)</span> at once, it will be wider at each <span class="math inline">\(X_{h}\)</span> than CIs for individual <span class="math inline">\(X_{h}\)</span>.</p>
</div>
<div id="analysis-of-variance-approach" class="section level2">
<h2><span class="header-section-number">3.7</span> Analysis of Variance Approach</h2>
<ul>
<li>Partitioning of Total Sum of Squares</li>
</ul>
<p><span class="math display">\[Y_{i} - \bar{Y} = \hat{Y}_{i} - \bar{Y} + Y_{i} - \hat{Y}_{i}\]</span></p>
<p><span class="math display">\[\sum (Y_{i} - \bar{Y})^{2} = \sum (\hat{Y}_{i} - \bar{Y})^{2} + \sum (Y_{i} - \hat{Y}_{i})^{2}\]</span></p>
<p><span class="math display">\[SSTO = SSR + SSE\]</span></p>
<p>SSTO stands for <strong>total sum of squares</strong>, SSE stands for <strong>error sum of squares</strong> and SSR stands for <strong>regression sum of squares</strong>.</p>
<ul>
<li>Breakdown of Degrees of Freedom</li>
</ul>
<p><span class="math display">\[n - 1 = 1 + (n - 2)\]</span></p>
<p>We have n-1 degrees of freedom associated with SSTO. SSE has n-2 degrees of freedom and SSR has 1 degree of freedom.</p>
<ul>
<li>Mean Squares</li>
</ul>
<p>A sum of squares divided by its associated degrees of freedom is called a <strong>mean square</strong> (MS)</p>
<p>The mean squares are not additive:</p>
<p><span class="math inline">\(\frac{SSTO}{n-1} \neq \frac{SSR}{1} + \frac{SSE}{n-2} = MSR + MSE\)</span></p>
<ul>
<li>ANalysis Of VAriance Table (ANOVA table)</li>
</ul>
<p><strong>ANOVA table</strong>: The breakdowns of the total sum of squares and associated degrees of freedom are displayed in the form of ANVOA.</p>
<p><strong>SSTOU</strong>: the total uncorrected sum of squares, <span class="math inline">\(\sum Y_i^2\)</span></p>
<p><strong>SS</strong>: correction for the mean sum of squares, <span class="math inline">\(n\bar{Y}^2\)</span></p>
<p><strong>SSTO</strong> = <span class="math inline">\(\sum (Y_i - \bar{Y})^2 = \sum Y_i^2 - n\bar{Y}^2 = SSTOU + SS\)</span></p>
<table>
<thead>
<tr class="header">
<th align="left">Source of Variation</th>
<th align="left">SS</th>
<th align="left">df</th>
<th align="left">MS</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Regression</td>
<td align="left"><span class="math inline">\(SSR = \sum(\hat{Y}_i - \bar{Y})^2\)</span></td>
<td align="left">1</td>
<td align="left"><span class="math inline">\(MSR = \frac{SSR}{1}\)</span></td>
</tr>
<tr class="even">
<td align="left">Error</td>
<td align="left"><span class="math inline">\(SSE = \sum(Y_i - \hat{Y}_i)^2\)</span></td>
<td align="left">n-2</td>
<td align="left"><span class="math inline">\(MSE = \frac{SSE}{n-2}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Total</td>
<td align="left"><span class="math inline">\(SSTO = \sum(Y_i - \bar{Y})^2\)</span></td>
<td align="left">n-1</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Correction for mean</td>
<td align="left"><span class="math inline">\(SS \text{(correction for mean)} = n\bar{Y}^2\)</span></td>
<td align="left">1</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Total, uncorrected</td>
<td align="left"><span class="math inline">\(SSTOU = \sum Y_i^2\)</span></td>
<td align="left">n</td>
<td align="left"></td>
</tr>
</tbody>
</table>
<ul>
<li>Expected Mean Squares</li>
</ul>
<p><span class="math display">\[E(MSE) = \sigma^2\]</span></p>
<p><span class="math display">\[E(MSR) = \sigma^2 + \beta_1^2 \sum (X_i - \bar{X})^2\]</span></p>
<ul>
<li>F test for <span class="math inline">\(\beta_1 = 0\)</span> versus <span class="math inline">\(\beta_1 \neq 0\)</span></li>
</ul>
<p>Test Statistic: <span class="math inline">\(F^* = \frac{MSR}{MSE} \sim F(1,n-2)\)</span></p>
</div>
<div id="general-linear-test-approach" class="section level2">
<h2><span class="header-section-number">3.8</span> General Linear Test Approach</h2>
<ul>
<li>Two models:
<ul>
<li><span class="math inline">\(Y_i = \beta_0 + \beta_2X_i + \varepsilon_i\)</span> (full model)</li>
<li><span class="math inline">\(Y_i = \beta_0 + \varepsilon_i\)</span> (reduced model under H0)</li>
</ul></li>
<li>F-statistic:</li>
</ul>
<p><span class="math display">\[F = \frac{(SSE(R) - SSE(F))/(df_R - df_F)}{SSE(F)/df_F}\]</span></p>
<p>The general linear teest approach can be used for highly complex tests of linear statistical models, as well as for simple tests. The basic steps in summary form are:</p>
<ol style="list-style-type: decimal">
<li>Fit the full model and obtain the error sum of squares SSE(F)</li>
<li>Fit the reduced model under H0 and obtain the error sum of squares SSE(R)</li>
<li>Use the test statistic and desicison rule</li>
</ol>
</div>
<div id="descriptive-measures-of-linear-association-between-x-and-y" class="section level2">
<h2><span class="header-section-number">3.9</span> Descriptive Measures of Linear Association between X and Y</h2>
<ul>
<li>Coefficient of Determination</li>
</ul>
<p><span class="math display">\[R^2 = \frac{SSR}{SSTO} = 1 - \frac{SSE}{SSTO}, 0 \leq R^2 \leq 1\]</span></p>
<ul>
<li>Limitations of <span class="math inline">\(R^2\)</span></li>
</ul>
<p>Tree common misunderstandings about <span class="math inline">\(R^2\)</span></p>
<ol style="list-style-type: decimal">
<li>A high coefficient of determination indicates that useful predictions can be made.</li>
<li>A high coefficient of determination indicates that the estimated regression line is a good fit.</li>
<li>A coefficient of determination near zero indicates that X and Y are not related.</li>
</ol>
<ul>
<li>Coefficient of Correlation</li>
</ul>
<p><span class="math display">\[r = \pm \sqrt{R^2}, -1 \leq r \leq 1\]</span></p>
</div>
<div id="considerations-in-applying-regression-analysis" class="section level2">
<h2><span class="header-section-number">3.10</span> Considerations in Applying Regression Analysis</h2>
</div>
<div id="normal-correlation-models" class="section level2">
<h2><span class="header-section-number">3.11</span> Normal Correlation Models</h2>
<ul>
<li>Distinction between Regression and Correlation Model</li>
<li>Bivariate Normal Distribution</li>
<li>Conditional Inferences</li>
<li>Inferences on Correlation Coefficients</li>
<li>Spearman Rank Correlation Coefficient</li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="linear-regression-with-one-predictor-variable.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="diagnostics-and-remedial-measures.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "none",
"toc_unnumbered": true,
"toc_depth": 1
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
